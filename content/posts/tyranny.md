+++
title = "The tyranny of numbers"
date = "2022-10-04T20:32:16+01:00"
author = "ssamot"
tags = ["AI", "Data", "Politics"]
description = "...AI and government"
+++

A problem I keep coming back to is one of the first things one notices when trying to analyse social science data; it is hard to come up with any concrete conclusion -- or, conversely, it is easy to make up any story you want, and have your data confirm it. It's trivial to keep adding confounders and claiming that "aha", this is confounded by X, which behaves like this and that, which you did not take into account when doing the study. In the same vein, one can selectively ignore confounders, present the right data (i.e.  [How to Lie with Statistics](https://www.goodreads.com/book/show/51291.How_to_Lie_with_Statistics) or [The Tyranny of Numbers: Mismeasurement and Misrule](https://www.goodreads.com/book/show/1651073.The_Tyranny_of_Numbers)) and make it deliver whatever you want to deliver. At this point, what even counts as inference? It's all made up, a theology of sorts on top of latent variables.

What drives these latent variables though? While the inference is lacking, a narrative is put together "that makes sense". A fiction, based on other fictions that are based on top of other fictions -- a latent space you can reason/plan in. How does one come up with this latent space might prove to be a central theme in AI.


{{< tweet user="ylecun" id="1577131592103133185" >}}
