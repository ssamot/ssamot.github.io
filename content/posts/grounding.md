+++
title = "Grounding large language models"
date = "2022-06-29T12:51:51+01:00"
author = "ssamot"
tags = ["Artificial Intelligence"]
description = "...might be achievable"
+++

I've came across this paper: [Mapping Language Models to Grounded Conceptual Spaces](https://openreview.net/pdf?id=gJcEM8sxHK) while searching for methods to address the problem of grounding large language models. Seems like the general approach is to feed the model data post-training. It's interesting, as it implies that you can learn from purely mental constructs link them to reality later on. 
