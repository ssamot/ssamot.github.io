+++
title = "All is matter in motion"
date = "2022-07-06T23:30:59+01:00"
author = "ssamot"
tags = ["AI", "Dialectics"]
description = "What to do next?"
+++

Dialectics is somewhat similar to multi-agent learning (or just multi-agent systems, without any learning), possibly combined with simulation based inference (i.e. you ground the models with data). Let's say you actually get to do the perfect simulation, you understand the all the laws of motion (i.e. the dynamics) of the system you are modelling in detail. Let's also say you have fully uncovered every sensible variable that goes into this system. The traditional Marxist (and Christian...) dictum is that this would be enough for you to change your course of action -- you shall know the truth and the truth shall set you free.

I somehow fail to see how this is the case. Sure, truth is nice to have, but why is it a motivator (in the RL rewarding sense)? If the truths uncovered preclude a specific set of actions that would maximise some notion of pleasure (preferably short term) from taking place, it becomes something interesting but of no value.

In the causal inference sense/RL sense, actions are embedded within the model you use. But because most of us are not actors in the world in the broader sense, it becomes really hard to have models where actions are encoded as part of the model. Which makes solving what to do next exceptionally hard.
