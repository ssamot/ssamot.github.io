<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Measures on ssamot's heretical rumblings</title><link>https://ssamot.me/tags/measures/</link><description>Recent content in Measures on ssamot's heretical rumblings</description><generator>Hugo</generator><language>en</language><copyright>Spyros Samothrakis</copyright><lastBuildDate>Mon, 16 May 2022 06:58:18 +0100</lastBuildDate><atom:link href="https://ssamot.me/tags/measures/index.xml" rel="self" type="application/rss+xml"/><item><title>Measures and fairness</title><link>https://ssamot.me/posts/mm/</link><pubDate>Mon, 16 May 2022 06:58:18 +0100</pubDate><guid>https://ssamot.me/posts/mm/</guid><description>&lt;p>A superb article popped in my twitter feed called &lt;a href="https://arxiv.org/pdf/1912.05511.pdf">Measurement and Fairness&lt;/a>. The article, as the title implies, deals with the imaginary quantities (e.g. teacher quality) and how operationalising them via actual measurements is where the problem of using metrics (I use the word interchangeably with &amp;ldquo;measures&amp;rdquo;) lies; in terms closer to AI/statistics, how to you link latent variables with observed variables. What strikes me is how fragile the notion of latent variable creation is; one can create whatever metric/measure they want, operationalise it in whatever way they think suits them and use enough force and propaganda to reshape the world according to their fiction. I tend to disagree with Chalmer that these &lt;a href="http://consc.net/papers/virtual.pdf">fictions created through latent variables are real&lt;/a>, at least they do not feel real to me, but one cannot but notice that their impact is very real and ranges from wars to going to the moon.&lt;/p></description></item><item><title>Measures tend to become targets</title><link>https://ssamot.me/posts/metrics/</link><pubDate>Sun, 15 May 2022 09:34:45 +0100</pubDate><guid>https://ssamot.me/posts/metrics/</guid><description>&lt;p>Most complaints about gaming a system can be traced back to &lt;a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Goodhart&amp;rsquo;s law&lt;/a>, i.e. &amp;ldquo;when a measure becomes a target, it ceases to be a good measure&amp;rdquo;. In the most trivial of scenarios, let us imagine that an oversight institution is created to measure the quality of teaching, and they come up with &amp;ldquo;average GPA&amp;rdquo;, which takes the mean of all student GPAs at a certain school. The minute this is measured and compiled in a table, someone will start ranking schools according to average GPA. School principals and education boards will see this and start competing on average GPAs, thus creating a target. Now, political pressures is going to be applied to the oversight institute to modify this target in ways that favours certain schools (e.g. combining average GPA with teaching hours) and from that point onwards its games and meta-games around fictional targets.&lt;/p></description></item></channel></rss>