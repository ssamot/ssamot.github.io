<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Reinforcement Learning on ssamot's heretical rumblings</title><link>https://ssamot.me/tags/reinforcement-learning/</link><description>Recent content in Reinforcement Learning on ssamot's heretical rumblings</description><generator>Hugo</generator><language>en</language><copyright>Spyros Samothrakis</copyright><lastBuildDate>Sun, 15 May 2022 09:34:45 +0100</lastBuildDate><atom:link href="https://ssamot.me/tags/reinforcement-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Measures tend to become targets</title><link>https://ssamot.me/posts/metrics/</link><pubDate>Sun, 15 May 2022 09:34:45 +0100</pubDate><guid>https://ssamot.me/posts/metrics/</guid><description>&lt;p>Most complaints about gaming a system can be traced back to &lt;a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Goodhart&amp;rsquo;s law&lt;/a>, i.e. &amp;ldquo;when a measure becomes a target, it ceases to be a good measure&amp;rdquo;. In the most trivial of scenarios, let us imagine that an oversight institution is created to measure the quality of teaching, and they come up with &amp;ldquo;average GPA&amp;rdquo;, which takes the mean of all student GPAs at a certain school. The minute this is measured and compiled in a table, someone will start ranking schools according to average GPA. School principals and education boards will see this and start competing on average GPAs, thus creating a target. Now, political pressures is going to be applied to the oversight institute to modify this target in ways that favours certain schools (e.g. combining average GPA with teaching hours) and from that point onwards its games and meta-games around fictional targets.&lt;/p></description></item></channel></rss>