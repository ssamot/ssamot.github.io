<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data science on ssamot's heretical rumblings</title><link>https://ssamot.me/tags/data-science/</link><description>Recent content in Data science on ssamot's heretical rumblings</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><copyright>Spyros Samothrakis</copyright><lastBuildDate>Thu, 23 Jun 2022 18:46:56 +0100</lastBuildDate><atom:link href="https://ssamot.me/tags/data-science/index.xml" rel="self" type="application/rss+xml"/><item><title>Simpson's paradox and horror of unobserved confounders</title><link>https://ssamot.me/posts/simpson/</link><pubDate>Thu, 23 Jun 2022 18:46:56 +0100</pubDate><guid>https://ssamot.me/posts/simpson/</guid><description>Let&amp;rsquo;s assume you have collected data from a hospital, where some patients are given a medicine and some are not. No experimental procedure was followed, you just collected whatever was out there and you want to check if taking the medicine causes improvements in health. With a bit of notational abuse, you want to check the effect of $T \rightarrow Y$. $T$ can be either 0 or 1 (whether someone was treated or not using the medicine), while $Y$ is a measurement of life quality &amp;ndash; the higher the better.</description></item><item><title>Cookie cutter data science</title><link>https://ssamot.me/posts/ccds/</link><pubDate>Thu, 23 Jun 2022 10:00:07 +0100</pubDate><guid>https://ssamot.me/posts/ccds/</guid><description>I &amp;rsquo;ve recently discovered https://github.com/drivendata/cookiecutter-data-science/ &amp;ndash; an effort to standardise the pipeline of a data science project. The practices proposed seem ideal to me &amp;ndash; from a very sane directory structure to discussing makefiles as project pipeline DAGs.
Not sure how I managed to survive using completely custom project templates for each project. In fact, I will argue, one should go ahead and automate the whole report/presentation generation pipeline. There aren&amp;rsquo;t that many data science patterns anyway (let&amp;rsquo;s say regression/classification/causal inference/time-series analysis/arbitrary optimisation), so it shouldn&amp;rsquo;t be that hard.</description></item></channel></rss>