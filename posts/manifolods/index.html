<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>The manifold hypothesis and text - ssamot's heretical rumblings</title><link rel=icon type=image/png href=/final_logo_purple_inv_sat.png><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="...and surprising things re: chatGPT"><meta property="og:image" content><meta property="og:title" content="The manifold hypothesis and text"><meta property="og:description" content="...and surprising things re: chatGPT"><meta property="og:type" content="article"><meta property="og:url" content="https://ssamot.me/posts/manifolods/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-02-17T07:50:32+00:00"><meta property="article:modified_time" content="2023-02-17T07:50:32+00:00"><meta property="og:site_name" content="ssamot's heretical rumblings"><meta name=twitter:card content="summary"><meta name=twitter:title content="The manifold hypothesis and text"><meta name=twitter:description content="...and surprising things re: chatGPT"><script src=https://ssamot.mejs/feather.min.js></script>
<link href=https://ssamot.me/css/fonts.352cefb34094cd6aeabccf0709d7c4006d075638fcd84db93818af5a51eec660.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://ssamot.me/css/main.74589d0801ac2e0077442cb10044eed50980086bdb7742d01991b816a420536d.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://ssamot.me/css/dark.512da9ec5e8a9c5da6bffed7d277ab45998fc7e791baebc0567864afdf75993d.css><script data-goatcounter=https://ssamot.goatcounter.com/count async src=//gc.zgo.at/count.js></script><noscript><img src="https://ssamot.goatcounter.com/count?p=/posts/manifolods"></noscript></head><body><div class=content><header><div class=main><a href=https://ssamot.me>ssamot's heretical rumblings</a></div><nav><a href=/about>about</a>
<a href=/contact>contact</a>
<a href=/posts>posts</a>
<a href=/publications>publications</a></nav></header><main><article><div class=title><h1 class=title>The manifold hypothesis and text</h1><div class=meta>Posted on Feb 17, 2023</div></div><section class=body><p>ChatGPT (and most GPT-like services) make up stuff all the time &ndash; it&rsquo;s not that surprising, and should not be that hard to fix. What is surprising is that language can be abstracted within them. In a sense, quantity has a quality of its own, and larger models do really well because they merely (!?) need to interpolate between training data examples.</p><p>I wonder if RL will have the same fate &ndash; there are some hints here and there: <a href="https://openreview.net/pdf?id=4-k7kUavAj">https://openreview.net/pdf?id=4-k7kUavAj</a>, but no conclusive answer yet. If this is done successfully it will basically mean that tons of data and big machines is all you need, a somewhat anti-climatic end to the AI saga.</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/artificial-intelligence>Artificial Intelligence</a></li></ul></nav></div></article></main><footer><div class=footer-info><a href=https://twitter.com/spysamot/>Twitter</a>
<a href=https://github.com/ssamot/>GitHub</a>&nbsp|| based on 

    <a href=https://gohugo.io>Hugo</a>/<a href=https://github.com/athul/archie>Archie</a> |
2023 Spyros Samothrakis |</div></footer><script>feather.replace()</script></div></body></html>