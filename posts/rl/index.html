<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Reinforcement learning - ssamot's heretical rumblings</title><link rel=icon type=image/png href=/final_logo_purple_inv_sat.png><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="..."><meta property="og:image" content><meta property="og:title" content="Reinforcement learning"><meta property="og:description" content="..."><meta property="og:type" content="article"><meta property="og:url" content="https://ssamot.me/posts/rl/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-04-15T12:09:59+01:00"><meta property="article:modified_time" content="2023-04-15T12:09:59+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Reinforcement learning"><meta name=twitter:description content="..."><script src=https://ssamot.mejs/feather.min.js></script><link href=https://ssamot.me/css/fonts.352cefb34094cd6aeabccf0709d7c4006d075638fcd84db93818af5a51eec660.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://ssamot.me/css/main.74589d0801ac2e0077442cb10044eed50980086bdb7742d01991b816a420536d.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://ssamot.me/css/dark.512da9ec5e8a9c5da6bffed7d277ab45998fc7e791baebc0567864afdf75993d.css><script data-goatcounter=https://ssamot.goatcounter.com/count async src=//gc.zgo.at/count.js></script><noscript><img src="https://ssamot.goatcounter.com/count?p=/posts/RL"></noscript></head><body><div class=content><header><div class=main><a href=https://ssamot.me>ssamot's heretical rumblings</a></div><nav><a href=/about>about</a>
<a href=/contact>contact</a>
<a href=/posts>posts</a>
<a href=/publications>publications</a></nav></header><main><article><div class=title><h1 class=title>Reinforcement learning</h1><div class=meta>Posted on Apr 15, 2023</div></div><section class=body><p>Deep down I am a control/RL junkie, but I&rsquo;ll give it to the NLP crowd, they have managed to turn AI mainstream and create a useful tool. It&rsquo;s not that we are not seeing really cool RL projects (see here: <a href=https://clemenswinter.com/2023/04/14/entity-based-reinforcement-learning/>https://clemenswinter.com/2023/04/14/entity-based-reinforcement-learning/</a>, here: <a href=https://github.com/NVIDIA-Omniverse/IsaacGymEnvs>https://github.com/NVIDIA-Omniverse/IsaacGymEnvs</a> and here: <a href=https://arxiv.org/abs/2304.01315)>https://arxiv.org/abs/2304.01315)</a>, it&rsquo;s that they do not have much use outside the lab (yet).</p><p>In a sense, we still do not have the killer RL application, and as I have said in another post, we will not get one unless zero-shot RL is solved.</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/artificial-intelligence>Artificial Intelligence</a></li></ul></nav></div></article></main><footer><div class=footer-info><a href=https://twitter.com/spysamot/>Twitter</a>
<a href=https://github.com/ssamot/>GitHub</a>&nbsp|| based on 

    <a href=https://gohugo.io>Hugo</a>/<a href=https://github.com/athul/archie>Archie</a> |
2023 Spyros Samothrakis |</div></footer><script>feather.replace()</script></div></body></html>