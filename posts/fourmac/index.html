<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>4 Maccabees and reinforcement learning - ssamot's heretical rumblings</title><link rel=icon type=image/png href=/final_logo_purple_inv_sat.png><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="..."><meta property="og:image" content><meta property="og:url" content="https://ssamot.me/posts/fourmac/"><meta property="og:site_name" content="ssamot's heretical rumblings"><meta property="og:title" content="4 Maccabees and reinforcement learning"><meta property="og:description" content="..."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-12-23T21:57:24+00:00"><meta property="article:modified_time" content="2022-12-23T21:57:24+00:00"><meta property="article:tag" content="Planning"><meta name=twitter:card content="summary"><meta name=twitter:title content="4 Maccabees and reinforcement learning"><meta name=twitter:description content="..."><script src=https://ssamot.me/js/feather.min.js></script><link href=https://ssamot.me/css/fonts.352cefb34094cd6aeabccf0709d7c4006d075638fcd84db93818af5a51eec660.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://ssamot.me/css/main.74589d0801ac2e0077442cb10044eed50980086bdb7742d01991b816a420536d.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://ssamot.me/css/dark.512da9ec5e8a9c5da6bffed7d277ab45998fc7e791baebc0567864afdf75993d.css><script data-goatcounter=https://ssamot.goatcounter.com/count async src=//gc.zgo.at/count.js></script><noscript><img src="https://ssamot.goatcounter.com/count?p=/posts/fourmac"></noscript></head><body><div class=content><header><div class=main><a href=https://ssamot.me/>ssamot's heretical rumblings</a></div><nav><a href=/about>about</a>
<a href=/contact>contact</a>
<a href=/posts>posts</a>
<a href=/publications>publications</a></nav></header><main><article><div class=title><h1 class=title>4 Maccabees and reinforcement learning</h1><div class=meta>Posted on Dec 23, 2022</div></div><section class=body><p>A little known book of Christian apocrypha, which I do not think is considered canonical by any church, is 4 Maccabees. The book reads like a proto-account of martyrdom, with its central theme being a treatise on how &ldquo;logic&rdquo; or &ldquo;rationality&rdquo; overcomes all passions. The author of the text claims that prime among the passions are pleasure and pain:</p><blockquote><p>(4 Macc 13:20) The two most comprehensive types of the passions are pleasure and pain, and each of these is by nature concerned with both body and soul</p></blockquote><p>He then goes to show how what he terms &ldquo;logic&rdquo; overcomes the passions. As with the rest of the Maccabee books, its main rhetorical device is Israelite resistance to Antiochus Epiphanes, a Seleucid king. In 4 Macc, Antiochus tries to feed pork to Eleazar, a local Israelite elder. Eleazar flat out refuses, and is tortured to death. Following his death, seven brothers are brought forward and asked to eat pork (no need to turn Greek says Antiochus, just eat a bit of pork). They all refuse and are put to death one by one, in the most gory ways possible, while their mother watches. She then commits suicide by tossing herself into the flames. There is no explicit claim as to what reward the brothers claim by their self-sacrifice, other than that they will be with the prophets and God.</p><p>As agents, it looks like the brothers and the elder are acting irrationally. They have such a strong preference for not eating pork, and thus not violating the Law, that no amount of pain or any promise of pleasure can make them forfeit it. I <em>guess</em> succumbing to Antiochus would be the equivalent of losing ones soul, living a life alienated by your own identity, but it says little about total reward.</p><p>It is not trivial to incorporate such behaviour in RL agents. Somehow V(s,horrible death) > V(s,pork). This can be made possible either be assuming some form of extreme afterlife reward (which does not seem to be in the text), or that eating pork changes the meaning/reward of all future external states. In this sense, eating pork is a special reward-modulating action, which changes the pleasure of everything that is to happen. This goes against the spirit of RL/game theory &ndash; the rewards are not defined by the agent, but by the environment. As an example, an agent is not allowed to change the winning state for chess. If that was the case, then both black and white agents could agree that they both win and finish the game after the first move. It also points out to a strategy of fanaticism for winning in real-world conflict. Unlike chess, where the rewards are fixed but it is hard to get in terms of how strategy, rewards are easy to get intellectually but hard to get morally.</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/planning>Planning</a></li></ul></nav></div></article></main><footer><div class=footer-info><a href=https://twitter.com/spysamot/>Twitter</a>
<a href=https://github.com/ssamot/>GitHub</a>&nbsp|| based on 

    <a href=https://gohugo.io>Hugo</a>/<a href=https://github.com/athul/archie>Archie</a> |
2025 Spyros Samothrakis |</div></footer><script>feather.replace()</script></div></body></html>