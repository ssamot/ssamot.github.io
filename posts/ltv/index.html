<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Labour theory of value through the lens of reinforcement learning - ssamot's heretical rumblings</title><link rel=icon type=image/png href=/final_logo_purple_inv_sat.png><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="Slavery in the high seas..."><meta property="og:image" content><meta property="og:url" content="https://ssamot.me/posts/ltv/"><meta property="og:site_name" content="ssamot's heretical rumblings"><meta property="og:title" content="Labour theory of value through the lens of reinforcement learning"><meta property="og:description" content="Slavery in the high seas..."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-06-13T07:09:59+01:00"><meta property="article:modified_time" content="2022-06-13T07:09:59+01:00"><meta property="article:tag" content="Socialism"><meta property="article:tag" content="Artificial Intelligence"><meta name=twitter:card content="summary"><meta name=twitter:title content="Labour theory of value through the lens of reinforcement learning"><meta name=twitter:description content="Slavery in the high seas..."><script src=https://ssamot.me/js/feather.min.js></script><link href=https://ssamot.me/css/fonts.352cefb34094cd6aeabccf0709d7c4006d075638fcd84db93818af5a51eec660.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://ssamot.me/css/main.74589d0801ac2e0077442cb10044eed50980086bdb7742d01991b816a420536d.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://ssamot.me/css/dark.512da9ec5e8a9c5da6bffed7d277ab45998fc7e791baebc0567864afdf75993d.css><script data-goatcounter=https://ssamot.goatcounter.com/count async src=//gc.zgo.at/count.js></script><noscript><img src="https://ssamot.goatcounter.com/count?p=/posts/LTV"></noscript></head><body><div class=content><header><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css integrity=sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js integrity=sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><div class=main><a href=https://ssamot.me/>ssamot's heretical rumblings</a></div><nav><a href=/about>about</a>
<a href=/contact>contact</a>
<a href=/posts>posts</a>
<a href=/publications>publications</a></nav></header><main><article><div class=title><h1 class=title>Labour theory of value through the lens of reinforcement learning</h1><div class=meta>Posted on Jun 13, 2022</div></div><section class=body><p>One of the popular online debates has been on the usefulness of the labour theory of value (LTV). I&rsquo;ll attempt to give LTV a reinforcement learning (RL) spin (that&rsquo;s how I understand it anyway) which should hopefully clarify things a bit. I&rsquo;ll also abuse notation.</p><p>Imagine a scenario where an agent (an abstraction of a capitalist, firm, upper management etc) has access to the following at every time step $t$:</p><ul><li>$o_t$ &ndash;> an observation the agent receives containing information about the <em>world</em> at time $t$</li><li>$a_t$ &ndash;> an action the agent does in time $t$, in this case choosing a <em>concept</em>, the amount/type of <em>labour</em> to use and the appropriate <em>resources</em>.</li><li>$R_t$ &ndash;> profit at time $t$</li><li>$B$ &ndash;> a belief function that maps from observations to internal states</li></ul><p>The (exchange) value is a hypothetical average of reward, referred to as the Q-value in RL:</p><p>$$Q^\pi(B(world)|concept, labour, resources) = E_\pi [R_t | (world, a_t = concept,labour, resources]$$</p><p>A <em>policy</em> is what the agent decides to do and is defined as:
$$\pi(B(world)|concept, labour, resources)$$</p><p>The agent will have to calibrate its beliefs to help it in its quest for long term reward (which is different than trying to understand the true state of the world, and has implications on consciousness &ndash; see <a href=https://www.theguardian.com/science/2021/aug/21/neuroscientist-anil-seth-we-risk-not-understanding-the-central-mystery-of-life>here</a> for my MSc supervisor&rsquo;s views), as well as discover the relevant concepts, find labour and grab resources. More precisely, the agent follows a process trying to do this:</p><p>$$\pi^* = \argmax_{B, concept, labour, resource}Q^\pi$$</p><p>The whole process seems to be producing commodities, but it it doesn&rsquo;t strictly have to. Assuming that the observable outcome of the process is a commodity it might be better to split things into multiple steps (instead of one) following a causal chain of concept &ndash;> (labour, resources) &ndash;> reward, but the above approximation of value as $Q^\pi$ and $\pi$ should be sufficient for now.</p><p>The agent samples the environment, receives observations, takes actions and tastes rewards. The state of the world has to be inferred through beliefs (it is never observed by anyone). The <em>concept</em> cannot be observed either. The value cannot be observed, all an individual agent perceives is profit. Note that an agent can lose money creating valuable commodities and make money creating commodities with zero or negative value. An agent can keep the process going for a long time if they can operate on negative profits. Because value is a long-term concept, one can also extract short term profits and destroy value completely - an elite university selling degrees would be an example of this.</p><p>A third party can use observable quantities such as prices, socially necessary labour time, wages, commodities (i.e. manifestations of concepts) and other byproducts of the process and infer value (this is often called &ldquo;off-policy RL&rdquo;), approximately. Could the agent have made all its profits without labour and resources? Absolutely not, but nobody is disputing this. Could the agent have extracted profit without a concept and a profit-maximising execution? I doubt anyone would dispute that either.</p><p>So where is all the confusion coming from? It comes from implicit definitions about justice. More specifically, one can easily discern two camps:</p><p>(a) The agent is worth ever penny</p><p>The agent deserves all reward. Any reasonable subjectivist would tell you that, yes, labour and resources are in the mix, but even if the agent pays labour peanuts and pocket all profit, that&rsquo;s fine they came up with the concept and executed the policy. It&rsquo;s the moral thing to do. Labour in the above formulation does not even have agency, it resembles a pool of extremely configurable robots. It deserves nothing outside the value-capture process (i.e. the agent&rsquo;s policy).</p><p>(b) The agent is stealing everything</p><p>A socialist would tell you that (paraphrasing Marx&rsquo; <a href=https://www.marxists.org/archive/marx/works/1875/gotha/>Critique of the Gotha Programme</a>) all wealth comes from labour and nature; the fact that an agent found itself in a position to play wizard does not mean they should be earning anything more than what they would have been paid from their own socially necessary labour time. In this view, the concept and policy are worth nothing. They are obvious, social constructs, the agent somehow inherited them; the only reason the agent is an agent in the first place is because of primitive accumulation and/or blind luck. The difference between the profit of the agent and the profit that goes to labour in the form of wages is theft. Doing the off-policy RL trick would tell you (more or less) how much the agent is stealing from labour.</p><p>Most post-1990s subjects fall into camp (a). They see economy as concepts and policy (i.e. what to make and how to make it), and all value derives from them. It is really hard to take position (b) seriously, as a naive causal reading (which most humans do by default) is that labour and nature <em>cause</em> value, absent of a concept and a policy, and this is evidently not true. What position (b) is really saying is that more or less anyone can be an agent, the problem is not that hard, it&rsquo;s just that the vast majority of people will never have the opportunity. If you sample a single labourer, you can turn them into CEO pretty quickly.
Socialists would put together various programmes forward to address the issue (planning, coops), but none has been that convincing so far, and solutions deserver another post. Overall, capturing value directly is not easy (we are probably not after exchange value either, it&rsquo;s use values we are after), and the proxy a society uses for value would change it drastically.</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/socialism>Socialism</a></li><li><a href=/tags/artificial-intelligence>Artificial Intelligence</a></li></ul></nav></div></article></main><footer><div class=footer-info><a href=https://twitter.com/spysamot/>Twitter</a>
<a href=https://github.com/ssamot/>GitHub</a>&nbsp|| based on 

    <a href=https://gohugo.io>Hugo</a>/<a href=https://github.com/athul/archie>Archie</a> |
2025 Spyros Samothrakis |</div></footer><script>feather.replace()</script></div></body></html>